{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6170939,"sourceType":"datasetVersion","datasetId":3540726}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nfrom pathlib import Path\nimport json\nfrom tqdm import tqdm\n\nclass MultiCameraFrameExtractor:\n    def __init__(self, dataset_root, output_root, frame_skip=5):\n        \"\"\"\n        Initialize Multi-Camera Frame Extractor\n        Args:\n            dataset_root: Path to dataset root (multiple_cameras_fall_dataset/)\n            output_root: Path to output directory for extracted frames\n            frame_skip: Extract every nth frame (default: 5)\n        \"\"\"\n        self.dataset_root = Path(dataset_root)\n        self.output_root = Path(output_root)\n        self.frame_skip = frame_skip\n        # Create output directories\n        self.create_output_structure()\n\n    def create_output_structure(self):\n        \"\"\"Create organized output directory structure\"\"\"\n        directories = [\n            'extracted_frames/fall',\n            'extracted_frames/no_fall', \n            'extracted_frames/by_scenario',\n            'extracted_frames/by_camera',\n            'metadata'\n        ]\n        for dir_path in directories:\n            (self.output_root / dir_path).mkdir(parents=True, exist_ok=True)\n        # Create camera-specific directories\n        for cam_id in range(1, 9):\n            (self.output_root / f'extracted_frames/by_camera/cam{cam_id}').mkdir(exist_ok=True)\n        # Create chute-specific directories  \n        for chute_id in range(1, 25):\n            (self.output_root / f'extracted_frames/by_scenario/chute_{chute_id:02d}').mkdir(exist_ok=True)\n\n    def extract_video_frames(self, video_path, output_dir, prefix=\"frame\"):\n        \"\"\"Extract frames from a single video file\"\"\"\n        cap = cv2.VideoCapture(str(video_path))\n        if not cap.isOpened():\n            print(f\"Error: Could not open video {video_path}\")\n            return []\n        fps = cap.get(cv2.CAP_PROP_FPS)\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        frame_count = 0\n        saved_frames = []\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                break\n            if frame_count % self.frame_skip == 0:\n                frame_filename = f\"{prefix}_{frame_count:06d}.jpg\"\n                frame_path = output_dir / frame_filename\n                cv2.imwrite(str(frame_path), frame)\n                saved_frames.append({\n                    'frame_path': str(frame_path),\n                    'frame_number': frame_count,\n                    'timestamp': frame_count / fps if fps > 0 else 0\n                })\n            frame_count += 1\n        cap.release()\n        return {\n            'video_path': str(video_path),\n            'total_frames': total_frames,\n            'extracted_frames': len(saved_frames),\n            'fps': fps,\n            'resolution': (width, height),\n            'saved_frames': saved_frames\n        }\n\n    def process_scenario(self, scenario_num):\n        \"\"\"Process all camera angles for a single chute (renamed from scenario)\"\"\"\n        chute_dir = self.dataset_root / f\"chute{scenario_num:02d}\"\n        if not chute_dir.exists():\n            print(f\"Warning: Chute directory {chute_dir} not found\")\n            return None\n        scenario_metadata = {\n            'scenario_id': scenario_num,\n            'is_fall': scenario_num <= 22,\n            'cameras': {}\n        }\n        for cam_id in range(1, 9):\n            video_extensions = ['.avi', '.mp4', '.mov', '.mkv']\n            video_path = None\n            for ext in video_extensions:\n                potential_path = chute_dir / f\"cam{cam_id}{ext}\"\n                if potential_path.exists():\n                    video_path = potential_path\n                    break\n            if video_path is None:\n                print(f\"Warning: Video for chute {scenario_num:02d}, cam{cam_id} not found\")\n                continue\n            scenario_output = self.output_root / f\"extracted_frames/by_scenario/chute_{scenario_num:02d}/cam{cam_id}\"\n            camera_output = self.output_root / f\"extracted_frames/by_camera/cam{cam_id}/chute_{scenario_num:02d}\"\n            scenario_output.mkdir(parents=True, exist_ok=True)\n            camera_output.mkdir(parents=True, exist_ok=True)\n            prefix = f\"chute{scenario_num:02d}_c{cam_id}\"\n            frame_metadata = self.extract_video_frames(video_path, scenario_output, prefix)\n            for frame_info in frame_metadata['saved_frames']:\n                src = Path(frame_info['frame_path'])\n                dst = camera_output / src.name\n                if not dst.exists():\n                    try:\n                        os.symlink(src, dst)\n                    except OSError:\n                        cv2.imwrite(str(dst), cv2.imread(str(src)))\n            scenario_metadata['cameras'][f'cam{cam_id}'] = frame_metadata\n            category = 'fall' if scenario_num <= 22 else 'no_fall'\n            category_output = self.output_root / f\"extracted_frames/{category}/chute_{scenario_num:02d}_cam{cam_id}\"\n            category_output.mkdir(parents=True, exist_ok=True)\n            for frame_info in frame_metadata['saved_frames']:\n                src = Path(frame_info['frame_path'])\n                dst = category_output / src.name\n                if not dst.exists():\n                    try:\n                        os.symlink(src, dst)\n                    except OSError:\n                        cv2.imwrite(str(dst), cv2.imread(str(src)))\n        return scenario_metadata\n\n    def process_all_scenarios(self):\n        all_metadata = {\n            'dataset_info': {\n                'total_scenarios': 24,\n                'fall_scenarios': 22,\n                'no_fall_scenarios': 2,\n                'cameras_per_scenario': 8,\n                'frame_skip': self.frame_skip\n            },\n            'scenarios': {}\n        }\n        print(f\"Processing Multiple Cameras Fall Dataset...\")\n        print(f\"Dataset root: {self.dataset_root}\")\n        print(f\"Output root: {self.output_root}\")\n        print(f\"Frame skip: {self.frame_skip}\")\n        print(\"=\"*60)\n        for scenario_num in tqdm(range(1, 25), desc=\"Processing scenarios\"):\n            scenario_metadata = self.process_scenario(scenario_num)\n            if scenario_metadata:\n                all_metadata['scenarios'][f'chute_{scenario_num:02d}'] = scenario_metadata\n        metadata_file = self.output_root / 'metadata/extraction_metadata.json'\n        with open(metadata_file, 'w') as f:\n            json.dump(all_metadata, f, indent=2)\n        print(f\"\\nFrame extraction completed!\")\n        print(f\"Metadata saved to: {metadata_file}\")\n        return all_metadata\n\n    def generate_summary_report(self, metadata):\n        total_frames = 0\n        total_videos = 0\n        fall_frames = 0\n        no_fall_frames = 0\n        for scenario_id, scenario_data in metadata['scenarios'].items():\n            scenario_num = int(scenario_id.split('_')[1])\n            is_fall = scenario_num <= 22\n            for cam_id, cam_data in scenario_data['cameras'].items():\n                total_videos += 1\n                extracted_frames = cam_data['extracted_frames']\n                total_frames += extracted_frames\n                if is_fall:\n                    fall_frames += extracted_frames\n                else:\n                    no_fall_frames += extracted_frames\n        report = f\"\"\"\nMULTI-CAMERA FALL DATASET EXTRACTION REPORT\n{'='*60}\nTotal Scenarios Processed: {len(metadata['scenarios'])}\nTotal Videos Processed: {total_videos}\nTotal Frames Extracted: {total_frames:,}\nFall Scenarios: {len([s for s in metadata['scenarios'].keys() if int(s.split('_')[1]) <= 22])}\nNo-Fall Scenarios: {len([s for s in metadata['scenarios'].keys() if int(s.split('_')[1]) > 22])}\nFall Frames: {fall_frames:,}\nNo-Fall Frames: {no_fall_frames:,}\nFrame Skip Used: {metadata['dataset_info']['frame_skip']}\nAverage Frames per Video: {total_frames/total_videos:.1f}\nOutput Structure:\n- extracted_frames/fall/          # Fall frames organized by chute+camera\n- extracted_frames/no_fall/       # No-fall frames organized by chute+camera  \n- extracted_frames/by_scenario/   # Frames organized by chute\n- extracted_frames/by_camera/     # Frames organized by camera angle\n- metadata/                       # Extraction metadata and logs\n        \"\"\"\n        report_file = self.output_root / 'metadata/extraction_report.txt'\n        with open(report_file, 'w') as f:\n            f.write(report)\n        print(report)\n        return report\n\n# Example usage\nif __name__ == \"__main__\":\n    extractor = MultiCameraFrameExtractor(\n        dataset_root=\"/kaggle/input/multiple-cameras-fall-dataset/dataset/dataset\",  # Your provided root path\n        output_root=\"processed_output/\",\n        frame_skip=5\n    )\n    metadata = extractor.process_all_scenarios()\n    extractor.generate_summary_report(metadata)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-01T16:42:46.014881Z","iopub.execute_input":"2025-09-01T16:42:46.015143Z","iopub.status.idle":"2025-09-01T16:43:11.066666Z","shell.execute_reply.started":"2025-09-01T16:42:46.015124Z","shell.execute_reply":"2025-09-01T16:43:11.065841Z"}},"outputs":[{"name":"stdout","text":"Processing Multiple Cameras Fall Dataset...\nDataset root: /kaggle/input/multiple-cameras-fall-dataset/dataset/dataset\nOutput root: processed_output\nFrame skip: 5\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Processing scenarios:   0%|          | 0/24 [00:00<?, ?it/s][mpeg4 @ 0x13c9e7c0] ac-tex damaged at 3 19\n[mpeg4 @ 0x13c9e7c0] Error at MB: 877\n[mpeg4 @ 0x13c86480] ac-tex damaged at 42 21\n[mpeg4 @ 0x13c86480] Error at MB: 1008\n[mpeg4 @ 0x13c9e7c0] ac-tex damaged at 24 17\n[mpeg4 @ 0x13c9e7c0] Error at MB: 806\n[mpeg4 @ 0x13c99880] ac-tex damaged at 13 23\n[mpeg4 @ 0x13c99880] Error at MB: 1071\n[mpeg4 @ 0x13c86500] ac-tex damaged at 8 12\n[mpeg4 @ 0x13c86500] Error at MB: 560\n[mpeg4 @ 0x141b90c0] ac-tex damaged at 12 17\n[mpeg4 @ 0x141b90c0] Error at MB: 794\n[mpeg4 @ 0x13cc3400] mcbpc damaged at 37 18\n[mpeg4 @ 0x13cc3400] Error at MB: 865\n[mpeg4 @ 0x13cc3300] Error at MB: 1285\nProcessing scenarios:   4%|▍         | 1/24 [00:11<04:25, 11.56s/it][mpeg4 @ 0x141d6f80] Error at MB: 898\n[mpeg4 @ 0x13c99a80] ac-tex damaged at 38 16\n[mpeg4 @ 0x13c99a80] Error at MB: 774\n[mpeg4 @ 0x13cc3100] mcbpc damaged at 30 8\n[mpeg4 @ 0x13cc3100] Error at MB: 398\n[mpeg4 @ 0x14046a40] ac-tex damaged at 43 21\n[mpeg4 @ 0x14046a40] Error at MB: 1009\n[mpeg4 @ 0x13d4b440] ac-tex damaged at 40 29\n[mpeg4 @ 0x13d4b440] Error at MB: 1374\n[mpeg4 @ 0x13c99a80] ac-tex damaged at 36 21\n[mpeg4 @ 0x13c99a80] Error at MB: 1002\n[mpeg4 @ 0x141d6d80] ac-tex damaged at 5 7\n[mpeg4 @ 0x141d6d80] Error at MB: 327\nProcessing scenarios:   8%|▊         | 2/24 [00:17<03:03,  8.35s/it][mpeg4 @ 0x13d0fc80] ac-tex damaged at 8 24\n[mpeg4 @ 0x13d0fc80] Error at MB: 1112\n[mpeg4 @ 0x141dc840] ac-tex damaged at 30 27\n[mpeg4 @ 0x141dc840] Error at MB: 1272\n[mpeg4 @ 0x13d0f580] ac-tex damaged at 21 13\n[mpeg4 @ 0x13d0f580] Error at MB: 619\n[mpeg4 @ 0x13cc2f00] ac-tex damaged at 10 23\n[mpeg4 @ 0x13cc2f00] Error at MB: 1068\n[mpeg4 @ 0x13d0fc80] ac-tex damaged at 8 27\n[mpeg4 @ 0x13d0fc80] Error at MB: 1250\n[mpeg4 @ 0x141dc640] ac-tex damaged at 10 25\n[mpeg4 @ 0x141dc640] Error at MB: 1160\n[mpeg4 @ 0x13cc30c0] ac-tex damaged at 25 21\n[mpeg4 @ 0x13cc30c0] Error at MB: 991\n[mpeg4 @ 0x141dc640] 2. marker bit missing in 3. esc\n[mpeg4 @ 0x141dc640] Error at MB: 749\nProcessing scenarios:  12%|█▎        | 3/24 [00:25<02:55,  8.34s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/44468467.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mframe_skip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     )\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_scenarios\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_summary_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/44468467.py\u001b[0m in \u001b[0;36mprocess_all_scenarios\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mscenario_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing scenarios\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mscenario_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_scenario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscenario_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mall_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scenarios'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'chute_{scenario_num:02d}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscenario_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/44468467.py\u001b[0m in \u001b[0;36mprocess_scenario\u001b[0;34m(self, scenario_num)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mcamera_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"chute{scenario_num:02d}_c{cam_id}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mframe_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_video_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mframe_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframe_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'saved_frames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frame_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/44468467.py\u001b[0m in \u001b[0;36mextract_video_frames\u001b[0;34m(self, video_path, output_dir, prefix)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mframe_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{prefix}_{frame_count:06d}.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mframe_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mframe_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 saved_frames.append({\n\u001b[1;32m     62\u001b[0m                     \u001b[0;34m'frame_path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nfrom pathlib import Path\nimport json\nfrom tqdm import tqdm\n\nclass MultiCameraFrameExtractor:\n    def __init__(self, dataset_root, output_root, frame_skip=5):\n        self.dataset_root = Path(dataset_root)\n        self.output_root = Path(output_root)\n        self.frame_skip = frame_skip\n        self.create_output_structure()\n\n    def create_output_structure(self):\n        directories = [\n            'extracted_frames/fall',\n            'extracted_frames/no_fall',\n            'extracted_frames/by_scenario',\n            'extracted_frames/by_camera',\n            'metadata'\n        ]\n        for dir_path in directories:\n            (self.output_root / dir_path).mkdir(parents=True, exist_ok=True)\n        for cam_id in range(1, 9):\n            (self.output_root / f'extracted_frames/by_camera/cam{cam_id}').mkdir(exist_ok=True)\n        for chute_id in range(1, 25):\n            (self.output_root / f'extracted_frames/by_scenario/chute_{chute_id:02d}').mkdir(exist_ok=True)\n\n    def extract_video_frames(self, video_path, output_dir, prefix=\"frame\"):\n        cap = cv2.VideoCapture(str(video_path))\n        if not cap.isOpened():\n            print(f\"Error: Could not open video {video_path}\")\n            return []\n        fps = cap.get(cv2.CAP_PROP_FPS)\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        frame_count = 0\n        saved_frames = []\n        consecutive_failures = 0  # To break if too many bad frames in a row\n        MAX_FAILURES = 10\n\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                consecutive_failures += 1\n                if consecutive_failures >= MAX_FAILURES:\n                    # Too many consecutive failures, break loop\n                    break\n                else:\n                    frame_count += 1\n                continue\n            else:\n                consecutive_failures = 0\n\n            if frame_count % self.frame_skip == 0:\n                frame_filename = f\"{prefix}_{frame_count:06d}.jpg\"\n                frame_path = output_dir / frame_filename\n                try:\n                    cv2.imwrite(str(frame_path), frame)\n                    saved_frames.append({\n                        'frame_path': str(frame_path),\n                        'frame_number': frame_count,\n                        'timestamp': frame_count / fps if fps > 0 else 0\n                    })\n                except Exception as e:\n                    print(f\"Warning: Could not save frame {frame_count} of video {video_path}: {e}\")\n            frame_count += 1\n\n        cap.release()\n        return {\n            'video_path': str(video_path),\n            'total_frames': total_frames,\n            'extracted_frames': len(saved_frames),\n            'fps': fps,\n            'resolution': (width, height),\n            'saved_frames': saved_frames\n        }\n\n    def process_scenario(self, scenario_num):\n        chute_dir = self.dataset_root / f\"chute{scenario_num:02d}\"\n        if not chute_dir.exists():\n            print(f\"Warning: Chute directory {chute_dir} not found\")\n            return None\n        scenario_metadata = {\n            'scenario_id': scenario_num,\n            'is_fall': scenario_num <= 22,\n            'cameras': {}\n        }\n        for cam_id in range(1, 9):\n            video_extensions = ['.avi', '.mp4', '.mov', '.mkv']\n            video_path = None\n            for ext in video_extensions:\n                potential_path = chute_dir / f\"cam{cam_id}{ext}\"\n                if potential_path.exists():\n                    video_path = potential_path\n                    break\n            if video_path is None:\n                print(f\"Warning: Video for chute {scenario_num:02d}, cam{cam_id} not found\")\n                continue\n            scenario_output = self.output_root / f\"extracted_frames/by_scenario/chute_{scenario_num:02d}/cam{cam_id}\"\n            camera_output = self.output_root / f\"extracted_frames/by_camera/cam{cam_id}/chute_{scenario_num:02d}\"\n            scenario_output.mkdir(parents=True, exist_ok=True)\n            camera_output.mkdir(parents=True, exist_ok=True)\n            prefix = f\"chute{scenario_num:02d}_c{cam_id}\"\n            frame_metadata = self.extract_video_frames(video_path, scenario_output, prefix)\n            for frame_info in frame_metadata['saved_frames']:\n                src = Path(frame_info['frame_path'])\n                dst = camera_output / src.name\n                if not dst.exists():\n                    try:\n                        os.symlink(src, dst)\n                    except OSError:\n                        cv2.imwrite(str(dst), cv2.imread(str(src)))\n            scenario_metadata['cameras'][f'cam{cam_id}'] = frame_metadata\n            category = 'fall' if scenario_num <= 22 else 'no_fall'\n            category_output = self.output_root / f\"extracted_frames/{category}/chute_{scenario_num:02d}_cam{cam_id}\"\n            category_output.mkdir(parents=True, exist_ok=True)\n            for frame_info in frame_metadata['saved_frames']:\n                src = Path(frame_info['frame_path'])\n                dst = category_output / src.name\n                if not dst.exists():\n                    try:\n                        os.symlink(src, dst)\n                    except OSError:\n                        cv2.imwrite(str(dst), cv2.imread(str(src)))\n        return scenario_metadata\n\n    def process_all_scenarios(self):\n        all_metadata = {\n            'dataset_info': {\n                'total_scenarios': 24,\n                'fall_scenarios': 22,\n                'no_fall_scenarios': 2,\n                'cameras_per_scenario': 8,\n                'frame_skip': self.frame_skip\n            },\n            'scenarios': {}\n        }\n        print(f\"Processing Multiple Cameras Fall Dataset...\")\n        print(f\"Dataset root: {self.dataset_root}\")\n        print(f\"Output root: {self.output_root}\")\n        print(f\"Frame skip: {self.frame_skip}\")\n        print(\"=\"*60)\n        for scenario_num in tqdm(range(1, 25), desc=\"Processing scenarios\"):\n            scenario_metadata = self.process_scenario(scenario_num)\n            if scenario_metadata:\n                all_metadata['scenarios'][f'chute_{scenario_num:02d}'] = scenario_metadata\n        metadata_file = self.output_root / 'metadata/extraction_metadata.json'\n        with open(metadata_file, 'w') as f:\n            json.dump(all_metadata, f, indent=2)\n        print(f\"\\nFrame extraction completed!\")\n        print(f\"Metadata saved to: {metadata_file}\")\n        return all_metadata\n\n    def generate_summary_report(self, metadata):\n        total_frames = 0\n        total_videos = 0\n        fall_frames = 0\n        no_fall_frames = 0\n        for scenario_id, scenario_data in metadata['scenarios'].items():\n            scenario_num = int(scenario_id.split('_')[1])\n            is_fall = scenario_num <= 22\n            for cam_id, cam_data in scenario_data['cameras'].items():\n                total_videos += 1\n                extracted_frames = cam_data['extracted_frames']\n                total_frames += extracted_frames\n                if is_fall:\n                    fall_frames += extracted_frames\n                else:\n                    no_fall_frames += extracted_frames\n        report = f\"\"\"\nMULTI-CAMERA FALL DATASET EXTRACTION REPORT\n{'='*60}\nTotal Scenarios Processed: {len(metadata['scenarios'])}\nTotal Videos Processed: {total_videos}\nTotal Frames Extracted: {total_frames:,}\nFall Scenarios: {len([s for s in metadata['scenarios'].keys() if int(s.split('_')[1]) <= 22])}\nNo-Fall Scenarios: {len([s for s in metadata['scenarios'].keys() if int(s.split('_')[1]) > 22])}\nFall Frames: {fall_frames:,}\nNo-Fall Frames: {no_fall_frames:,}\nFrame Skip Used: {metadata['dataset_info']['frame_skip']}\nAverage Frames per Video: {total_frames / total_videos:.1f}\nOutput Structure:\n- extracted_frames/fall/          # Fall frames organized by chute+camera\n- extracted_frames/no_fall/       # No-fall frames organized by chute+camera  \n- extracted_frames/by_scenario/   # Frames organized by chute\n- extracted_frames/by_camera/     # Frames organized by camera angle\n- metadata/                       # Extraction metadata and logs\n        \"\"\"\n        report_file = self.output_root / 'metadata/extraction_report.txt'\n        with open(report_file, 'w') as f:\n            f.write(report)\n        print(report)\n        return report\n\nif __name__ == \"__main__\":\n    extractor = MultiCameraFrameExtractor(\n        dataset_root=\"/kaggle/input/multiple-cameras-fall-dataset/dataset/dataset\",\n        output_root=\"processed_output/\",\n        frame_skip=5\n    )\n    metadata = extractor.process_all_scenarios()\n    extractor.generate_summary_report(metadata)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T16:45:22.491797Z","iopub.execute_input":"2025-09-01T16:45:22.492090Z","iopub.status.idle":"2025-09-01T16:50:01.018970Z","shell.execute_reply.started":"2025-09-01T16:45:22.492070Z","shell.execute_reply":"2025-09-01T16:50:01.018392Z"}},"outputs":[{"name":"stdout","text":"Processing Multiple Cameras Fall Dataset...\nDataset root: /kaggle/input/multiple-cameras-fall-dataset/dataset/dataset\nOutput root: processed_output\nFrame skip: 5\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Processing scenarios:   0%|          | 0/24 [00:00<?, ?it/s][mpeg4 @ 0x1425c9c0] ac-tex damaged at 3 19\n[mpeg4 @ 0x1425c9c0] Error at MB: 877\n[mpeg4 @ 0x14046d40] ac-tex damaged at 42 21\n[mpeg4 @ 0x14046d40] Error at MB: 1008\n[mpeg4 @ 0x13d4b3c0] ac-tex damaged at 24 17\n[mpeg4 @ 0x13d4b3c0] Error at MB: 806\n[mpeg4 @ 0x14046d40] ac-tex damaged at 13 23\n[mpeg4 @ 0x14046d40] Error at MB: 1071\n[mpeg4 @ 0x14046d40] ac-tex damaged at 8 12\n[mpeg4 @ 0x14046d40] Error at MB: 560\n[mpeg4 @ 0x1425c9c0] ac-tex damaged at 12 17\n[mpeg4 @ 0x1425c9c0] Error at MB: 794\n[mpeg4 @ 0x13fee4c0] mcbpc damaged at 37 18\n[mpeg4 @ 0x13fee4c0] Error at MB: 865\n[mpeg4 @ 0x13d4b3c0] Error at MB: 1285\nProcessing scenarios:   4%|▍         | 1/24 [00:30<11:33, 30.16s/it][mpeg4 @ 0x13ecc8c0] Error at MB: 898\n[mpeg4 @ 0x14046d40] ac-tex damaged at 38 16\n[mpeg4 @ 0x14046d40] Error at MB: 774\n[mpeg4 @ 0x13c84800] mcbpc damaged at 30 8\n[mpeg4 @ 0x13c84800] Error at MB: 398\n[mpeg4 @ 0x13c7e8c0] ac-tex damaged at 43 21\n[mpeg4 @ 0x13c7e8c0] Error at MB: 1009\n[mpeg4 @ 0x13d4b000] ac-tex damaged at 40 29\n[mpeg4 @ 0x13d4b000] Error at MB: 1374\n[mpeg4 @ 0x141b6500] ac-tex damaged at 36 21\n[mpeg4 @ 0x141b6500] Error at MB: 1002\n[mpeg4 @ 0x1425c9c0] ac-tex damaged at 5 7\n[mpeg4 @ 0x1425c9c0] Error at MB: 327\nProcessing scenarios:   8%|▊         | 2/24 [00:43<07:19, 19.99s/it][mpeg4 @ 0x14046d40] ac-tex damaged at 8 24\n[mpeg4 @ 0x14046d40] Error at MB: 1112\n[mpeg4 @ 0x13e5f040] ac-tex damaged at 30 27\n[mpeg4 @ 0x13e5f040] Error at MB: 1272\n[mpeg4 @ 0x14046d40] ac-tex damaged at 21 13\n[mpeg4 @ 0x14046d40] Error at MB: 619\n[mpeg4 @ 0x13d4b000] ac-tex damaged at 10 23\n[mpeg4 @ 0x13d4b000] Error at MB: 1068\n[mpeg4 @ 0x141a04c0] ac-tex damaged at 8 27\n[mpeg4 @ 0x141a04c0] Error at MB: 1250\n[mpeg4 @ 0x1425c9c0] ac-tex damaged at 10 25\n[mpeg4 @ 0x1425c9c0] Error at MB: 1160\n[mpeg4 @ 0x13e5b840] ac-tex damaged at 25 21\n[mpeg4 @ 0x13e5b840] Error at MB: 991\n[mpeg4 @ 0x14046d40] 2. marker bit missing in 3. esc\n[mpeg4 @ 0x14046d40] Error at MB: 749\nProcessing scenarios:  12%|█▎        | 3/24 [00:57<06:03, 17.31s/it][mpeg4 @ 0x141b8700] ac-tex damaged at 9 20\n[mpeg4 @ 0x141b8700] Error at MB: 929\n[mpeg4 @ 0x13d4b000] ac-tex damaged at 6 27\n[mpeg4 @ 0x13d4b000] Error at MB: 1248\n[mpeg4 @ 0x14046d40] ac-tex damaged at 33 27\n[mpeg4 @ 0x14046d40] Error at MB: 1275\n[mpeg4 @ 0x141b8700] ac-tex damaged at 8 23\n[mpeg4 @ 0x141b8700] Error at MB: 1066\n[mpeg4 @ 0x141b8700] ac-tex damaged at 11 15\n[mpeg4 @ 0x141b8700] Error at MB: 701\n[mpeg4 @ 0x141b8700] Error at MB: 1250\n[mpeg4 @ 0x13a521c0] Error at MB: 732\n[mpeg4 @ 0x14220380] Error at MB: 849\nProcessing scenarios:  17%|█▋        | 4/24 [01:04<04:29, 13.48s/it][mpeg4 @ 0x141b8700] ac-tex damaged at 22 17\n[mpeg4 @ 0x141b8700] Error at MB: 804\n[mpeg4 @ 0x13c7e240] mcbpc damaged at 20 25\n[mpeg4 @ 0x13c7e240] Error at MB: 1170\n[mpeg4 @ 0x13ecc8c0] ac-tex damaged at 33 7\n[mpeg4 @ 0x13ecc8c0] Error at MB: 355\n[mpeg4 @ 0x141b8700] ac-tex damaged at 1 21\n[mpeg4 @ 0x141b8700] Error at MB: 967\n[mpeg4 @ 0x1425c9c0] ac-tex damaged at 42 19\n[mpeg4 @ 0x1425c9c0] Error at MB: 916\n[mpeg4 @ 0x13ecc8c0] ac-tex damaged at 42 17\n[mpeg4 @ 0x13ecc8c0] Error at MB: 824\n[mpeg4 @ 0x14447a80] mcbpc damaged at 41 27\n[mpeg4 @ 0x14447a80] Error at MB: 1283\n[mpeg4 @ 0x13e5b840] ac-tex damaged at 40 10\n[mpeg4 @ 0x13e5b840] Error at MB: 500\nProcessing scenarios:  21%|██        | 5/24 [01:10<03:22, 10.65s/it][mpeg4 @ 0x13ecc8c0] ac-tex damaged at 14 21\n[mpeg4 @ 0x13ecc8c0] Error at MB: 980\n[mpeg4 @ 0x13e5b840] ac-tex damaged at 0 29\n[mpeg4 @ 0x13e5b840] Error at MB: 1334\n[mpeg4 @ 0x13e5b840] P cbpy damaged at 41 27\n[mpeg4 @ 0x13e5b840] Error at MB: 1283\n[mpeg4 @ 0x141b8700] Error at MB: 1095\n[mpeg4 @ 0x13ecc8c0] Error at MB: 857\n[mpeg4 @ 0x14046d40] ac-tex damaged at 7 11\n[mpeg4 @ 0x14046d40] Error at MB: 513\n[mpeg4 @ 0x141b8700] mcbpc damaged at 14 25\n[mpeg4 @ 0x141b8700] Error at MB: 1164\nProcessing scenarios:  25%|██▌       | 6/24 [01:20<03:06, 10.38s/it][mpeg4 @ 0x141b8700] ac-tex damaged at 5 22\n[mpeg4 @ 0x141b8700] Error at MB: 1017\n[mpeg4 @ 0x13e5b840] ac-tex damaged at 36 18\n[mpeg4 @ 0x13e5b840] Error at MB: 864\n[mpeg4 @ 0x13da7a40] ac-tex damaged at 30 27\n[mpeg4 @ 0x13da7a40] Error at MB: 1272\n[mpeg4 @ 0x13da7a40] ac-tex damaged at 44 21\n[mpeg4 @ 0x13da7a40] Error at MB: 1010\n[mpeg4 @ 0x13e5b840] I cbpy damaged at 20 27\n[mpeg4 @ 0x13e5b840] Error at MB: 1262\n[mpeg4 @ 0x141b8700] mcbpc damaged at 18 20\n[mpeg4 @ 0x141b8700] Error at MB: 938\n[mpeg4 @ 0x13e5b840] ac-tex damaged at 37 26\n[mpeg4 @ 0x13e5b840] Error at MB: 1233\n[mpeg4 @ 0x13da7a40] Error at MB: 943\nProcessing scenarios:  29%|██▉       | 7/24 [01:27<02:36,  9.21s/it][mpeg4 @ 0x14220380] ac-tex damaged at 4 17\n[mpeg4 @ 0x14220380] Error at MB: 786\n[mpeg4 @ 0x141b8700] ac-tex damaged at 20 6\n[mpeg4 @ 0x141b8700] Error at MB: 296\n[mpeg4 @ 0x13e5adc0] ac-tex damaged at 6 8\n[mpeg4 @ 0x13e5adc0] Error at MB: 374\n[mpeg4 @ 0x14220380] ac-tex damaged at 30 26\n[mpeg4 @ 0x14220380] Error at MB: 1226\n[mpeg4 @ 0x14220380] ac-tex damaged at 8 14\n[mpeg4 @ 0x14220380] Error at MB: 652\n[mpeg4 @ 0x14604ac0] ac-tex damaged at 7 19\n[mpeg4 @ 0x14604ac0] Error at MB: 881\n[mpeg4 @ 0x14604ac0] ac-tex damaged at 19 21\n[mpeg4 @ 0x14604ac0] Error at MB: 985\n[mpeg4 @ 0x14220380] ac-tex damaged at 35 22\n[mpeg4 @ 0x14220380] Error at MB: 1047\nProcessing scenarios:  33%|███▎      | 8/24 [01:32<02:06,  7.92s/it][mpeg4 @ 0x14220380] ac-tex damaged at 23 2\n[mpeg4 @ 0x14220380] Error at MB: 115\n[mpeg4 @ 0x13da7a40] ac-tex damaged at 4 29\n[mpeg4 @ 0x13da7a40] Error at MB: 1338\n[mpeg4 @ 0x13da7a40] ac-tex damaged at 13 14\n[mpeg4 @ 0x13da7a40] Error at MB: 657\n[mpeg4 @ 0x14604ac0] ac-tex damaged at 35 7\n[mpeg4 @ 0x14604ac0] Error at MB: 357\n[mpeg4 @ 0x13da7a40] Error at MB: 1184\n[mpeg4 @ 0x14220380] ac-tex damaged at 37 3\n[mpeg4 @ 0x14220380] Error at MB: 175\n[mpeg4 @ 0x13da7a40] ac-tex damaged at 6 22\n[mpeg4 @ 0x13da7a40] Error at MB: 1018\nProcessing scenarios:  38%|███▊      | 9/24 [01:39<01:53,  7.57s/it][mpeg4 @ 0x13f0c1c0] Error at MB: 920\n[mpeg4 @ 0x13f0c1c0] ac-tex damaged at 6 28\n[mpeg4 @ 0x13f0c1c0] Error at MB: 1294\n[mpeg4 @ 0x13f0c1c0] ac-tex damaged at 36 21\n[mpeg4 @ 0x13f0c1c0] Error at MB: 1002\n[mpeg4 @ 0x13dcb240] ac-tex damaged at 12 29\n[mpeg4 @ 0x13dcb240] Error at MB: 1346\n[mpeg4 @ 0x14220380] ac-tex damaged at 16 15\n[mpeg4 @ 0x14220380] Error at MB: 706\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 33 18\n[mpeg4 @ 0x13a515c0] Error at MB: 861\n[mpeg4 @ 0x14466f80] Error at MB: 117\n[mpeg4 @ 0x14467040] ac-tex damaged at 42 13\n[mpeg4 @ 0x14467040] Error at MB: 640\nProcessing scenarios:  42%|████▏     | 10/24 [01:45<01:43,  7.36s/it][mpeg4 @ 0x13dd1b00] ac-tex damaged at 32 16\n[mpeg4 @ 0x13dd1b00] Error at MB: 768\n[mpeg4 @ 0x14220380] ac-tex damaged at 5 28\n[mpeg4 @ 0x14220380] Error at MB: 1293\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 11 25\n[mpeg4 @ 0x13a515c0] Error at MB: 1161\n[mpeg4 @ 0x14467b00] ac-tex damaged at 38 22\n[mpeg4 @ 0x14467b00] Error at MB: 1050\n[mpeg4 @ 0x14220380] Error at MB: 1174\n[mpeg4 @ 0x141b6800] ac-tex damaged at 10 18\n[mpeg4 @ 0x141b6800] Error at MB: 838\n[mpeg4 @ 0x14467b00] ac-tex damaged at 40 23\n[mpeg4 @ 0x14467b00] Error at MB: 1098\n[mpeg4 @ 0x13a515c0] Error at MB: 1048\nProcessing scenarios:  46%|████▌     | 11/24 [01:51<01:30,  6.97s/it][mpeg4 @ 0x14467b00] mcbpc damaged at 23 28\n[mpeg4 @ 0x14467b00] Error at MB: 1311\n[mpeg4 @ 0x141b5d00] ac-tex damaged at 16 16\n[mpeg4 @ 0x141b5d00] Error at MB: 752\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 7 20\n[mpeg4 @ 0x13a515c0] Error at MB: 927\n[mpeg4 @ 0x13ec7400] ac-tex damaged at 26 27\n[mpeg4 @ 0x13ec7400] Error at MB: 1268\n[mpeg4 @ 0x14604ac0] mcbpc damaged at 32 25\n[mpeg4 @ 0x14604ac0] Error at MB: 1182\n[mpeg4 @ 0x14467b00] Error at MB: 1190\n[mpeg4 @ 0x14220380] ac-tex damaged at 28 19\n[mpeg4 @ 0x14220380] Error at MB: 902\n[mpeg4 @ 0x14604ac0] Error at MB: 1012\nProcessing scenarios:  50%|█████     | 12/24 [01:58<01:22,  6.89s/it][mpeg4 @ 0x14467b00] ac-tex damaged at 22 17\n[mpeg4 @ 0x14467b00] Error at MB: 804\n[mpeg4 @ 0x13a515c0] Error at MB: 470\n[mpeg4 @ 0x141b6800] ac-tex damaged at 17 23\n[mpeg4 @ 0x141b6800] Error at MB: 1075\n[mpeg4 @ 0x14467b00] ac-tex damaged at 26 21\n[mpeg4 @ 0x14467b00] Error at MB: 992\n[mpeg4 @ 0x141b6800] ac-tex damaged at 18 9\n[mpeg4 @ 0x141b6800] Error at MB: 432\n[mpeg4 @ 0x141b6800] ac-tex damaged at 27 24\n[mpeg4 @ 0x141b6800] Error at MB: 1131\n[mpeg4 @ 0x14467b00] ac-tex damaged at 37 3\n[mpeg4 @ 0x14467b00] Error at MB: 175\n[mpeg4 @ 0x14220380] ac-tex damaged at 37 18\n[mpeg4 @ 0x14220380] Error at MB: 865\nProcessing scenarios:  54%|█████▍    | 13/24 [02:07<01:22,  7.50s/it][mpeg4 @ 0x14220380] ac-tex damaged at 6 20\n[mpeg4 @ 0x14220380] Error at MB: 926\n[mpeg4 @ 0x14467b00] ac-tex damaged at 38 8\n[mpeg4 @ 0x14467b00] Error at MB: 406\n[mpeg4 @ 0x14604ac0] ac-tex damaged at 18 20\n[mpeg4 @ 0x14604ac0] Error at MB: 938\n[mpeg4 @ 0x14467b00] ac-tex damaged at 40 27\n[mpeg4 @ 0x14467b00] Error at MB: 1282\n[mpeg4 @ 0x14220380] ac-tex damaged at 12 13\n[mpeg4 @ 0x14220380] Error at MB: 610\n[mpeg4 @ 0x13da5600] ac-tex damaged at 3 13\n[mpeg4 @ 0x13da5600] Error at MB: 601\n[mpeg4 @ 0x14220380] ac-tex damaged at 21 23\n[mpeg4 @ 0x14220380] Error at MB: 1079\nProcessing scenarios:  58%|█████▊    | 14/24 [02:18<01:24,  8.45s/it][mpeg4 @ 0x14467b00] ac-tex damaged at 0 27\n[mpeg4 @ 0x14467b00] Error at MB: 1242\n[mpeg4 @ 0x141b6800] ac-tex damaged at 3 26\n[mpeg4 @ 0x141b6800] Error at MB: 1199\n[mpeg4 @ 0x14467b00] ac-tex damaged at 4 29\n[mpeg4 @ 0x14467b00] Error at MB: 1338\n[mpeg4 @ 0x141b6800] illegal dc vlc\n[mpeg4 @ 0x141b6800] Error at MB: 361\n[mpeg4 @ 0x141b6800] ac-tex damaged at 26 12\n[mpeg4 @ 0x141b6800] Error at MB: 578\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 38 8\n[mpeg4 @ 0x13a515c0] Error at MB: 406\n[mpeg4 @ 0x141b6800] ac-tex damaged at 13 28\n[mpeg4 @ 0x141b6800] Error at MB: 1301\n[mpeg4 @ 0x14467b00] Error at MB: 994\nProcessing scenarios:  62%|██████▎   | 15/24 [02:26<01:15,  8.38s/it][mpeg4 @ 0x141b6800] ac-tex damaged at 18 17\n[mpeg4 @ 0x141b6800] Error at MB: 800\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 32 20\n[mpeg4 @ 0x13a515c0] Error at MB: 952\n[mpeg4 @ 0x14467b00] ac-tex damaged at 8 10\n[mpeg4 @ 0x14467b00] Error at MB: 468\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 12 12\n[mpeg4 @ 0x13a515c0] Error at MB: 564\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 6 19\n[mpeg4 @ 0x13a515c0] Error at MB: 880\n[mpeg4 @ 0x14220380] ac-tex damaged at 10 25\n[mpeg4 @ 0x14220380] Error at MB: 1160\n[mpeg4 @ 0x141b6800] mcbpc damaged at 6 22\n[mpeg4 @ 0x141b6800] Error at MB: 1018\n[mpeg4 @ 0x141b6800] ac-tex damaged at 17 21\n[mpeg4 @ 0x141b6800] Error at MB: 983\nProcessing scenarios:  67%|██████▋   | 16/24 [02:36<01:10,  8.83s/it][mpeg4 @ 0x14467b00] ac-tex damaged at 43 13\n[mpeg4 @ 0x14467b00] Error at MB: 641\n[mpeg4 @ 0x14220380] ac-tex damaged at 10 15\n[mpeg4 @ 0x14220380] Error at MB: 700\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 28 23\n[mpeg4 @ 0x13a515c0] Error at MB: 1086\n[mpeg4 @ 0x141b6800] ac-tex damaged at 34 27\n[mpeg4 @ 0x141b6800] Error at MB: 1276\n[mpeg4 @ 0x14220380] ac-tex damaged at 13 12\n[mpeg4 @ 0x14220380] Error at MB: 565\n[mpeg4 @ 0x13ec60c0] ac-tex damaged at 32 4\n[mpeg4 @ 0x13ec60c0] Error at MB: 216\n[mpeg4 @ 0x14467b00] I cbpy damaged at 29 29\n[mpeg4 @ 0x14467b00] Error at MB: 1363\n[mpeg4 @ 0x14220380] ac-tex damaged at 32 25\n[mpeg4 @ 0x14220380] Error at MB: 1182\nProcessing scenarios:  71%|███████   | 17/24 [02:48<01:08,  9.80s/it][mpeg4 @ 0x141b6800] P cbpy damaged at 21 6\n[mpeg4 @ 0x141b6800] Error at MB: 297\n[mpeg4 @ 0x14467b00] ac-tex damaged at 2 26\n[mpeg4 @ 0x14467b00] Error at MB: 1198\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 19 28\n[mpeg4 @ 0x13a515c0] Error at MB: 1307\n[mpeg4 @ 0x141b6800] ac-tex damaged at 27 8\n[mpeg4 @ 0x141b6800] Error at MB: 395\n[mpeg4 @ 0x141b6800] ac-tex damaged at 2 21\n[mpeg4 @ 0x141b6800] Error at MB: 968\n[mpeg4 @ 0x141b6800] Error at MB: 656\n[mpeg4 @ 0x14467b00] I cbpy damaged at 0 27\n[mpeg4 @ 0x14467b00] Error at MB: 1242\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 5 17\n[mpeg4 @ 0x13a515c0] Error at MB: 787\nProcessing scenarios:  75%|███████▌  | 18/24 [02:56<00:55,  9.18s/it][mpeg4 @ 0x14467b00] ac-tex damaged at 11 8\n[mpeg4 @ 0x14467b00] Error at MB: 379\n[mpeg4 @ 0x14220380] ac-tex damaged at 9 22\n[mpeg4 @ 0x14220380] Error at MB: 1021\n[mpeg4 @ 0x141b6800] ac-tex damaged at 22 28\n[mpeg4 @ 0x141b6800] Error at MB: 1310\n[mpeg4 @ 0x14220380] mcbpc damaged at 2 6\n[mpeg4 @ 0x14220380] Error at MB: 278\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 44 18\n[mpeg4 @ 0x13a515c0] Error at MB: 872\n[mpeg4 @ 0x141b6800] ac-tex damaged at 26 16\n[mpeg4 @ 0x141b6800] Error at MB: 762\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 36 15\n[mpeg4 @ 0x13a515c0] Error at MB: 726\n[mpeg4 @ 0x13a515c0] Error at MB: 860\nProcessing scenarios:  79%|███████▉  | 19/24 [03:03<00:43,  8.69s/it][mpeg4 @ 0x14220380] ac-tex damaged at 13 12\n[mpeg4 @ 0x14220380] Error at MB: 565\n[mpeg4 @ 0x14220380] ac-tex damaged at 9 21\n[mpeg4 @ 0x14220380] Error at MB: 975\n[mpeg4 @ 0x141b6800] mcbpc damaged at 42 27\n[mpeg4 @ 0x141b6800] Error at MB: 1284\n[mpeg4 @ 0x13a515c0] illegal dc vlc\n[mpeg4 @ 0x13a515c0] Error at MB: 969\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 4 19\n[mpeg4 @ 0x13a515c0] Error at MB: 878\n[mpeg4 @ 0x145eda40] ac-tex damaged at 11 15\n[mpeg4 @ 0x145eda40] Error at MB: 701\n[mpeg4 @ 0x14220380] ac-tex damaged at 30 19\n[mpeg4 @ 0x14220380] Error at MB: 904\n[mpeg4 @ 0x14467b00] ac-tex damaged at 9 24\n[mpeg4 @ 0x14467b00] Error at MB: 1113\nProcessing scenarios:  83%|████████▎ | 20/24 [03:11<00:33,  8.31s/it][mpeg4 @ 0x13a515c0] ac-tex damaged at 7 19\n[mpeg4 @ 0x13a515c0] Error at MB: 881\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 11 8\n[mpeg4 @ 0x13a515c0] Error at MB: 379\n[mpeg4 @ 0x141b6800] Error at MB: 82\n[mpeg4 @ 0x141b6800] mcbpc damaged at 18 26\n[mpeg4 @ 0x141b6800] Error at MB: 1214\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 13 12\n[mpeg4 @ 0x13a515c0] Error at MB: 565\n[mpeg4 @ 0x14220380] ac-tex damaged at 29 20\n[mpeg4 @ 0x14220380] Error at MB: 949\n[mpeg4 @ 0x14467b00] ac-tex damaged at 14 21\n[mpeg4 @ 0x14467b00] Error at MB: 980\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 23 22\n[mpeg4 @ 0x13a515c0] Error at MB: 1035\nProcessing scenarios:  88%|████████▊ | 21/24 [03:19<00:25,  8.48s/it][mpeg4 @ 0x141b6800] ac-tex damaged at 1 5\n[mpeg4 @ 0x141b6800] Error at MB: 231\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 10 22\n[mpeg4 @ 0x13a515c0] Error at MB: 1022\n[mpeg4 @ 0x14220380] ac-tex damaged at 42 24\n[mpeg4 @ 0x14220380] Error at MB: 1146\n[mpeg4 @ 0x14467b00] ac-tex damaged at 3 19\n[mpeg4 @ 0x14467b00] Error at MB: 877\n[mpeg4 @ 0x14467b00] ac-tex damaged at 36 17\n[mpeg4 @ 0x14467b00] Error at MB: 818\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 9 26\n[mpeg4 @ 0x13a515c0] Error at MB: 1205\n[mpeg4 @ 0x14220380] Error at MB: 1350\n[mpeg4 @ 0x14467b00] P cbpy damaged at 32 18\n[mpeg4 @ 0x14467b00] Error at MB: 860\nProcessing scenarios:  92%|█████████▏| 22/24 [03:28<00:17,  8.55s/it][mpeg4 @ 0x13e5f3c0] ac-tex damaged at 9 27\n[mpeg4 @ 0x13e5f3c0] Error at MB: 1251\n[mpeg4 @ 0x14467b00] mcbpc damaged at 9 27\n[mpeg4 @ 0x14467b00] Error at MB: 1251\n[mpeg4 @ 0x14220380] illegal dc vlc\n[mpeg4 @ 0x14220380] Error at MB: 304\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 10 9\n[mpeg4 @ 0x13a515c0] Error at MB: 424\n[mpeg4 @ 0x1419cc00] ac-tex damaged at 40 25\n[mpeg4 @ 0x1419cc00] Error at MB: 1190\n[mpeg4 @ 0x13a515c0] ac-tex damaged at 44 15\n[mpeg4 @ 0x13a515c0] Error at MB: 734\n[mpeg4 @ 0x1419cc00] ac-tex damaged at 34 25\n[mpeg4 @ 0x1419cc00] Error at MB: 1184\nProcessing scenarios:  96%|█████████▌| 23/24 [04:09<00:18, 18.13s/it][mpeg4 @ 0x14220380] ac-tex damaged at 11 17\n[mpeg4 @ 0x14220380] Error at MB: 793\n[mpeg4 @ 0x141b6800] ac-tex damaged at 11 13\n[mpeg4 @ 0x141b6800] Error at MB: 609\n[mpeg4 @ 0x13a515c0] mcbpc damaged at 29 22\n[mpeg4 @ 0x13a515c0] Error at MB: 1041\n[mpeg4 @ 0x141b6800] ac-tex damaged at 8 1\n[mpeg4 @ 0x141b6800] Error at MB: 54\n[mpeg4 @ 0x1419cc00] P cbpy damaged at 42 17\n[mpeg4 @ 0x1419cc00] Error at MB: 824\n[mpeg4 @ 0x14467b00] ac-tex damaged at 24 15\n[mpeg4 @ 0x14467b00] Error at MB: 714\n[mpeg4 @ 0x14467b00] ac-tex damaged at 9 21\n[mpeg4 @ 0x14467b00] Error at MB: 975\n[mpeg4 @ 0x14467b00] ac-tex damaged at 32 9\n[mpeg4 @ 0x14467b00] Error at MB: 446\nProcessing scenarios: 100%|██████████| 24/24 [04:38<00:00, 11.59s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nFrame extraction completed!\nMetadata saved to: processed_output/metadata/extraction_metadata.json\n\nMULTI-CAMERA FALL DATASET EXTRACTION REPORT\n============================================================\nTotal Scenarios Processed: 24\nTotal Videos Processed: 192\nTotal Frames Extracted: 52,306\nFall Scenarios: 22\nNo-Fall Scenarios: 2\nFall Frames: 37,776\nNo-Fall Frames: 14,530\nFrame Skip Used: 5\nAverage Frames per Video: 272.4\nOutput Structure:\n- extracted_frames/fall/          # Fall frames organized by chute+camera\n- extracted_frames/no_fall/       # No-fall frames organized by chute+camera  \n- extracted_frames/by_scenario/   # Frames organized by chute\n- extracted_frames/by_camera/     # Frames organized by camera angle\n- metadata/                       # Extraction metadata and logs\n        \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\n# Multi-Camera Fall Dataset Preprocessing Pipeline\nimport cv2\nimport numpy as np\nfrom pathlib import Path\nimport json\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom tqdm import tqdm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nclass MultiCameraPreprocessor:\n    def __init__(self, frames_root, output_root, target_size=(224, 224)):\n        \"\"\"\n        Initialize Multi-Camera Preprocessor\n\n        Args:\n            frames_root: Path to extracted frames directory\n            output_root: Path to output directory for preprocessed data\n            target_size: Target image size (height, width)\n        \"\"\"\n        self.frames_root = Path(frames_root)\n        self.output_root = Path(output_root)\n        self.target_size = target_size\n\n        # Create output directories\n        self.create_output_structure()\n\n        # Initialize augmentation transforms\n        self.setup_transforms()\n\n    def create_output_structure(self):\n        \"\"\"Create organized output directory structure\"\"\"\n        directories = [\n            'preprocessed_frames/train/fall',\n            'preprocessed_frames/train/no_fall',\n            'preprocessed_frames/val/fall', \n            'preprocessed_frames/val/no_fall',\n            'preprocessed_frames/test/fall',\n            'preprocessed_frames/test/no_fall',\n            'augmented_frames/fall',\n            'augmented_frames/no_fall',\n            'normalized_frames',\n            'metadata',\n            'statistics'\n        ]\n\n        for dir_path in directories:\n            (self.output_root / dir_path).mkdir(parents=True, exist_ok=True)\n\n    def setup_transforms(self):\n        \"\"\"Setup image augmentation and preprocessing transforms\"\"\"\n        # Basic preprocessing (resize, normalize)\n        self.basic_transform = A.Compose([\n            A.Resize(height=self.target_size[0], width=self.target_size[1]),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet stats\n        ])\n\n        # Training augmentation (includes data augmentation)\n        self.train_transform = A.Compose([\n            A.Resize(height=int(self.target_size[0] * 1.1), width=int(self.target_size[1] * 1.1)),\n            A.RandomCrop(height=self.target_size[0], width=self.target_size[1]),\n            A.HorizontalFlip(p=0.5),\n            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n            A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.3),\n            A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.3),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n        # Validation/test transform (no augmentation)\n        self.val_transform = A.Compose([\n            A.Resize(height=self.target_size[0], width=self.target_size[1]),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n    def load_and_preprocess_image(self, image_path, transform=None):\n        \"\"\"Load and preprocess a single image\"\"\"\n        try:\n            # Load image\n            image = cv2.imread(str(image_path))\n            if image is None:\n                print(f\"Warning: Could not load image {image_path}\")\n                return None\n\n            # Convert BGR to RGB\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n            # Apply transforms\n            if transform is not None:\n                transformed = transform(image=image)\n                image = transformed['image']\n            else:\n                # Default resize if no transform specified\n                image = cv2.resize(image, (self.target_size[1], self.target_size[0]))\n                image = image.astype(np.float32) / 255.0\n\n            return image\n\n        except Exception as e:\n            print(f\"Error processing image {image_path}: {e}\")\n            return None\n\n    def calculate_dataset_statistics(self):\n        \"\"\"Calculate mean and std of the dataset for normalization\"\"\"\n        print(\"Calculating dataset statistics...\")\n\n        all_pixels = []\n\n        # Process fall frames\n        fall_dir = self.frames_root / 'extracted_frames/fall'\n        if fall_dir.exists():\n            for img_path in tqdm(list(fall_dir.rglob('*.jpg')), desc=\"Processing fall images\"):\n                img = cv2.imread(str(img_path))\n                if img is not None:\n                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                    img = cv2.resize(img, (self.target_size[1], self.target_size[0]))\n                    all_pixels.append(img.reshape(-1, 3))\n\n        # Process no-fall frames  \n        no_fall_dir = self.frames_root / 'extracted_frames/no_fall'\n        if no_fall_dir.exists():\n            for img_path in tqdm(list(no_fall_dir.rglob('*.jpg')), desc=\"Processing no-fall images\"):\n                img = cv2.imread(str(img_path))\n                if img is not None:\n                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                    img = cv2.resize(img, (self.target_size[1], self.target_size[0]))\n                    all_pixels.append(img.reshape(-1, 3))\n\n        if all_pixels:\n            all_pixels = np.vstack(all_pixels).astype(np.float32) / 255.0\n\n            mean = np.mean(all_pixels, axis=0)\n            std = np.std(all_pixels, axis=0)\n\n            stats = {\n                'mean': mean.tolist(),\n                'std': std.tolist(),\n                'total_pixels': len(all_pixels),\n                'image_size': self.target_size\n            }\n\n            # Save statistics\n            stats_file = self.output_root / 'statistics/dataset_stats.json'\n            with open(stats_file, 'w') as f:\n                json.dump(stats, f, indent=2)\n\n            print(f\"Dataset statistics saved to {stats_file}\")\n            print(f\"Mean: {mean}\")\n            print(f\"Std: {std}\")\n\n            return stats\n        else:\n            print(\"No images found for statistics calculation\")\n            return None\n\n    def create_train_val_test_split(self, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n        \"\"\"Create train/validation/test splits\"\"\"\n\n        # Collect all scenarios\n        fall_scenarios = list(range(1, 23))  # scenarios 01-22\n        no_fall_scenarios = list(range(23, 25))  # scenarios 23-24\n\n        # Split fall scenarios\n        np.random.shuffle(fall_scenarios)\n        n_fall = len(fall_scenarios)\n        fall_train_end = int(n_fall * train_ratio)\n        fall_val_end = fall_train_end + int(n_fall * val_ratio)\n\n        fall_train = fall_scenarios[:fall_train_end]\n        fall_val = fall_scenarios[fall_train_end:fall_val_end]\n        fall_test = fall_scenarios[fall_val_end:]\n\n        # For no-fall scenarios (only 2), use them for testing\n        no_fall_train = []\n        no_fall_val = []\n        no_fall_test = no_fall_scenarios\n\n        splits = {\n            'train': {\n                'fall': fall_train,\n                'no_fall': no_fall_train\n            },\n            'val': {\n                'fall': fall_val,\n                'no_fall': no_fall_val\n            },\n            'test': {\n                'fall': fall_test,\n                'no_fall': no_fall_test\n            }\n        }\n\n        # Save split information\n        split_file = self.output_root / 'metadata/data_splits.json'\n        with open(split_file, 'w') as f:\n            json.dump(splits, f, indent=2)\n\n        print(f\"Data splits saved to {split_file}\")\n        return splits\n\n    def process_scenario_images(self, scenario_num, is_fall, split_type, transform):\n        \"\"\"Process all images for a specific scenario\"\"\"\n        scenario_dir = self.frames_root / f'extracted_frames/{\"fall\" if is_fall else \"no_fall\"}'\n\n        processed_count = 0\n\n        # Find all scenario directories (scenario_XX_camY)\n        scenario_pattern = f\"scenario_{scenario_num:02d}_cam*\"\n        for scenario_cam_dir in scenario_dir.glob(scenario_pattern):\n            if not scenario_cam_dir.is_dir():\n                continue\n\n            # Process all images in this scenario+camera combination\n            for img_path in scenario_cam_dir.glob('*.jpg'):\n                # Load and preprocess image\n                processed_img = self.load_and_preprocess_image(img_path, transform)\n\n                if processed_img is not None:\n                    # Generate output filename\n                    output_filename = f\"{scenario_cam_dir.name}_{img_path.stem}.npy\"\n\n                    # Save processed image\n                    label = 'fall' if is_fall else 'no_fall'\n                    output_path = self.output_root / f'preprocessed_frames/{split_type}/{label}/{output_filename}'\n\n                    np.save(output_path, processed_img)\n                    processed_count += 1\n\n        return processed_count\n\n    def preprocess_all_data(self):\n        \"\"\"Preprocess all extracted frames\"\"\"\n        print(\"Starting comprehensive preprocessing...\")\n\n        # Calculate dataset statistics\n        stats = self.calculate_dataset_statistics()\n\n        # Create data splits\n        splits = self.create_train_val_test_split()\n\n        # Process each split\n        total_processed = 0\n        processing_log = {}\n\n        for split_name, split_data in splits.items():\n            print(f\"\\nProcessing {split_name} split...\")\n\n            # Select appropriate transform\n            if split_name == 'train':\n                transform = self.train_transform\n            else:\n                transform = self.val_transform\n\n            split_processed = 0\n            processing_log[split_name] = {'fall': 0, 'no_fall': 0}\n\n            # Process fall scenarios\n            for scenario_num in tqdm(split_data['fall'], desc=f\"{split_name} fall scenarios\"):\n                count = self.process_scenario_images(scenario_num, True, split_name, transform)\n                split_processed += count\n                processing_log[split_name]['fall'] += count\n\n            # Process no-fall scenarios\n            for scenario_num in tqdm(split_data['no_fall'], desc=f\"{split_name} no-fall scenarios\"):\n                count = self.process_scenario_images(scenario_num, False, split_name, transform)\n                split_processed += count\n                processing_log[split_name]['no_fall'] += count\n\n            total_processed += split_processed\n            print(f\"{split_name} split: {split_processed} images processed\")\n\n        # Save processing log\n        log_file = self.output_root / 'metadata/preprocessing_log.json'\n        with open(log_file, 'w') as f:\n            json.dump(processing_log, f, indent=2)\n\n        print(f\"\\nTotal images preprocessed: {total_processed}\")\n        print(f\"Processing log saved to {log_file}\")\n\n        return processing_log\n\n    def generate_augmented_data(self, augmentation_factor=3):\n        \"\"\"Generate additional augmented samples for training\"\"\"\n        print(f\"Generating augmented data (factor: {augmentation_factor})...\")\n\n        train_fall_dir = self.output_root / 'preprocessed_frames/train/fall'\n        augmented_fall_dir = self.output_root / 'augmented_frames/fall'\n\n        if not train_fall_dir.exists():\n            print(\"No training fall data found. Run preprocess_all_data() first.\")\n            return\n\n        # Heavy augmentation transform\n        heavy_aug = A.Compose([\n            A.Resize(height=int(self.target_size[0] * 1.2), width=int(self.target_size[1] * 1.2)),\n            A.RandomCrop(height=self.target_size[0], width=self.target_size[1]),\n            A.HorizontalFlip(p=0.7),\n            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n            A.GaussianBlur(blur_limit=(3, 7), p=0.5),\n            A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=25, val_shift_limit=15, p=0.5),\n            A.RandomGamma(gamma_limit=(70, 130), p=0.5),\n            A.CLAHE(clip_limit=3.0, tile_grid_size=(8, 8), p=0.5),\n            A.GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, p=0.3),\n            A.MotionBlur(blur_limit=7, p=0.3),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n        augmented_count = 0\n\n        for img_path in tqdm(list(train_fall_dir.glob('*.npy')), desc=\"Creating augmented samples\"):\n            # Load preprocessed image (denormalize first)\n            img = np.load(img_path)\n\n            # Denormalize for augmentation\n            mean = np.array([0.485, 0.456, 0.406])\n            std = np.array([0.229, 0.224, 0.225])\n            img = img * std + mean\n            img = (img * 255).astype(np.uint8)\n\n            # Generate multiple augmented versions\n            for aug_idx in range(augmentation_factor):\n                try:\n                    augmented = heavy_aug(image=img)['image']\n\n                    # Save augmented image\n                    output_filename = f\"aug{aug_idx}_{img_path.stem}.npy\"\n                    output_path = augmented_fall_dir / output_filename\n\n                    np.save(output_path, augmented)\n                    augmented_count += 1\n\n                except Exception as e:\n                    print(f\"Error augmenting {img_path}: {e}\")\n                    continue\n\n        print(f\"Generated {augmented_count} augmented samples\")\n        return augmented_count\n\n    def create_data_loaders_metadata(self):\n        \"\"\"Create metadata for data loading\"\"\"\n        metadata = {\n            'dataset_info': {\n                'name': 'Multiple Cameras Fall Dataset',\n                'total_scenarios': 24,\n                'cameras_per_scenario': 8,\n                'target_size': self.target_size,\n                'classes': ['fall', 'no_fall'],\n                'num_classes': 2\n            },\n            'preprocessing': {\n                'normalization_mean': [0.485, 0.456, 0.406],\n                'normalization_std': [0.229, 0.224, 0.225],\n                'augmentation_applied': True,\n                'target_image_size': self.target_size\n            },\n            'file_structure': {\n                'train': 'preprocessed_frames/train/',\n                'val': 'preprocessed_frames/val/',\n                'test': 'preprocessed_frames/test/',\n                'augmented': 'augmented_frames/'\n            }\n        }\n\n        # Count files in each split\n        for split in ['train', 'val', 'test']:\n            split_dir = self.output_root / f'preprocessed_frames/{split}'\n            metadata[f'{split}_counts'] = {}\n\n            for class_name in ['fall', 'no_fall']:\n                class_dir = split_dir / class_name\n                if class_dir.exists():\n                    count = len(list(class_dir.glob('*.npy')))\n                    metadata[f'{split}_counts'][class_name] = count\n\n        # Save metadata\n        metadata_file = self.output_root / 'metadata/data_loader_metadata.json'\n        with open(metadata_file, 'w') as f:\n            json.dump(metadata, f, indent=2)\n\n        print(f\"Data loader metadata saved to {metadata_file}\")\n        return metadata\n\n# Example usage\nif __name__ == \"__main__\":\n    # Initialize preprocessor\n    preprocessor = MultiCameraPreprocessor(\n        frames_root=\"processed_output/\",  # From frame extraction step\n        output_root=\"preprocessed_output/\",\n        target_size=(224, 224)  # Standard input size for most models\n    )\n\n    # Run complete preprocessing pipeline\n    print(\"Starting Multi-Camera Fall Dataset Preprocessing Pipeline\")\n    print(\"=\"*60)\n\n    # Step 1: Preprocess all data with train/val/test splits\n    processing_log = preprocessor.preprocess_all_data()\n\n    # Step 2: Generate augmented data for better training\n    augmented_count = preprocessor.generate_augmented_data(augmentation_factor=3)\n\n    # Step 3: Create metadata for data loaders\n    loader_metadata = preprocessor.create_data_loaders_metadata()\n\n    print(\"\\nPreprocessing pipeline completed successfully!\")\n    print(\"Ready for skeletal structure detection and model training.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport os\nfrom pathlib import Path\n\n# Root folder\nroot_folder = '/kaggle/input/multiple-cameras-fall-dataset/dataset/dataset/chute01'\n\n# Folder to save extracted and preprocessed frames\noutput_folder = '/kaggle/working/processed_output/extracted_frames/falls/chute_01_cam3'\nos.makedirs(output_folder, exist_ok=True)\n\n# Function to preprocess frames (example: convert to grayscale and resize)\ndef preprocess_frame(frame):\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    resized = cv2.resize(gray, (224, 224))\n    return resized\n\n# Extract and preprocess frames from videos in root folder\nfor root, dirs, files in os.walk(root_folder):\n    for file in files:\n        if file.lower().endswith(('.mp4', '.avi', '.mov')):\n            video_path = os.path.join(root, file)\n            cap = cv2.VideoCapture(video_path)\n            frame_count = 0\n            while cap.isOpened():\n                ret, frame = cap.read()\n                if not ret:\n                    break\n                # Preprocess frame\n                preprocessed_frame = preprocess_frame(frame)\n                # Save frame as image\n                frame_filename = f'{file.split(\".\")[0]}_{frame_count:06d}.jpg'\n                cv2.imwrite(os.path.join(output_folder, frame_filename), preprocessed_frame)\n                frame_count += 1\n            cap.release()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T17:03:16.808130Z","iopub.execute_input":"2025-09-01T17:03:16.808398Z","iopub.status.idle":"2025-09-01T17:03:39.583496Z","shell.execute_reply.started":"2025-09-01T17:03:16.808377Z","shell.execute_reply":"2025-09-01T17:03:39.582722Z"}},"outputs":[{"name":"stderr","text":"[mpeg4 @ 0x41253540] mcbpc damaged at 37 18\n[mpeg4 @ 0x41253540] Error at MB: 865\n[mpeg4 @ 0x40f09380] ac-tex damaged at 24 17\n[mpeg4 @ 0x40f09380] Error at MB: 806\n[mpeg4 @ 0x3fe9be00] ac-tex damaged at 13 23\n[mpeg4 @ 0x3fe9be00] Error at MB: 1071\n[mpeg4 @ 0x4104a040] ac-tex damaged at 12 17\n[mpeg4 @ 0x4104a040] Error at MB: 794\n[mpeg4 @ 0x40f09180] Error at MB: 1285\n[mpeg4 @ 0x40f54ac0] ac-tex damaged at 8 12\n[mpeg4 @ 0x40f54ac0] Error at MB: 560\n[mpeg4 @ 0x40e51c00] ac-tex damaged at 3 19\n[mpeg4 @ 0x40e51c00] Error at MB: 877\n[mpeg4 @ 0x40f8dc40] ac-tex damaged at 42 21\n[mpeg4 @ 0x40f8dc40] Error at MB: 1008\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import cv2\nimport mediapipe as mp\n\nmp_pose = mp.solutions.pose\nmp_drawing = mp.solutions.drawing_utils\n\ndef process_video_with_skeleton(video_path, output_path):\n    cap = cv2.VideoCapture(video_path)\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = cap.get(cv2.CAP_PROP_FPS)\n\n    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        results = pose.process(image_rgb)\n\n        if results.pose_landmarks:\n            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nvideo_path = '/kaggle/input/multiple-cameras-fall-dataset/dataset/dataset/chute01/cam1.avi'  # Replace with actual file\noutput_path = '/kaggle/working/skeleton_output.avi'\nprocess_video_with_skeleton(video_path, output_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T17:09:25.506350Z","iopub.execute_input":"2025-09-01T17:09:25.506697Z","iopub.status.idle":"2025-09-01T17:10:06.348822Z","shell.execute_reply.started":"2025-09-01T17:09:25.506673Z","shell.execute_reply":"2025-09-01T17:10:06.348116Z"}},"outputs":[{"name":"stderr","text":"W0000 00:00:1756746565.620625     127 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1756746565.675208     127 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1756746565.783370     128 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n[mpeg4 @ 0x17b4da00] ac-tex damaged at 3 19\n[mpeg4 @ 0x17b4da00] Error at MB: 877\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import cv2\nimport mediapipe as mp\nimport math\n\nmp_pose = mp.solutions.pose\nmp_drawing = mp.solutions.drawing_utils\n\ndef calculate_angle(a, b, c):\n    \"\"\"Calculate angle between three points a, b, c (each a tuple of x,y).\"\"\"\n    a = (a[0], a[1])\n    b = (b[0], b[1])\n    c = (c[0], c[1])\n\n    ab = (a[0] - b[0], a[1] - b[1])\n    cb = (c[0] - b[0], c[1] - b[1])\n\n    dot = ab[0]*cb[0] + ab[1]*cb[1]\n    mag_ab = math.sqrt(ab[0]**2 + ab[1]**2)\n    mag_cb = math.sqrt(cb[0]**2 + cb[1]**2)\n\n    if mag_ab * mag_cb == 0:\n        return 0\n\n    angle = math.acos(dot/(mag_ab*mag_cb))\n    return math.degrees(angle)\n\ndef is_fall(pose_landmarks, image_height):\n    # Get key points: left shoulder, right shoulder, left hip, right hip\n    left_shoulder = pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n    right_shoulder = pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n    left_hip = pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP]\n    right_hip = pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP]\n\n    # Midpoints of shoulders and hips\n    shoulder_mid_y = (left_shoulder.y + right_shoulder.y) / 2 * image_height\n    hip_mid_y = (left_hip.y + right_hip.y) / 2 * image_height\n\n    # Vertical distance between shoulders and hips (in pixels)\n    vertical_dist = hip_mid_y - shoulder_mid_y\n\n    # Approximate body angle wrt vertical (simplified as line between mid-shoulder and mid-hip)\n    # Use image coordinates (x,y), y increases downwards\n    shoulder_mid = ((left_shoulder.x + right_shoulder.x)/2, (left_shoulder.y + right_shoulder.y)/2)\n    hip_mid = ((left_hip.x + right_hip.x)/2, (left_hip.y + right_hip.y)/2)\n\n    # Angle with respect to vertical axis\n    dx = hip_mid[0] - shoulder_mid[0]\n    dy = hip_mid[1] - shoulder_mid[1]\n    angle = abs(math.degrees(math.atan2(dy, dx)) - 90)  # Angle difference from vertical line\n\n    # Heuristic fall detection thresholds\n    # For example, large horizontal body (angle > 45 deg) or very small vertical distance can indicate fall\n    if angle > 45 or vertical_dist < image_height * 0.1:\n        return True\n    return False\n\ndef process_video_with_fall_detection(video_path, output_path):\n    cap = cv2.VideoCapture(video_path)\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = cap.get(cv2.CAP_PROP_FPS)\n\n    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        results = pose.process(image_rgb)\n\n        fall_detected = False\n        if results.pose_landmarks:\n            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n            fall_detected = is_fall(results.pose_landmarks, height)\n\n            if fall_detected:\n                cv2.putText(frame, 'Fall Detected', (30, 60), cv2.FONT_HERSHEY_SIMPLEX,\n                            1.5, (0, 0, 255), 3)\n            else:\n                cv2.putText(frame, 'No Fall', (30, 60), cv2.FONT_HERSHEY_SIMPLEX,\n                            1.5, (0, 255, 0), 3)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\n# Usage\nvideo_path = '/kaggle/input/multiple-cameras-fall-dataset/dataset/dataset/chute01/cam2.avi'\noutput_path = '/kaggle/working/fall_detection_output.avi'\nprocess_video_with_fall_detection(video_path, output_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T17:13:36.343511Z","iopub.execute_input":"2025-09-01T17:13:36.344267Z","iopub.status.idle":"2025-09-01T17:14:13.257831Z","shell.execute_reply.started":"2025-09-01T17:13:36.344240Z","shell.execute_reply":"2025-09-01T17:14:13.257018Z"}},"outputs":[{"name":"stderr","text":"W0000 00:00:1756746816.465691     136 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1756746816.531230     139 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n[mpeg4 @ 0x1f80f540] ac-tex damaged at 42 21\n[mpeg4 @ 0x1f80f540] Error at MB: 1008\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}